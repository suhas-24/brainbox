# =================================================================
# AI FORGE ADVANCED LLM TEMPLATE - MODEL CONFIGURATION
# =================================================================

models:
  # Primary Models Configuration
  primary:
    provider: "openai"
    model: "gpt-4-turbo-preview"
    temperature: 0.7
    max_tokens: 4000
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    timeout: 60
    
  # Fallback Model Configuration
  fallback:
    provider: "anthropic"
    model: "claude-3-sonnet-20240229"
    temperature: 0.7
    max_tokens: 4000
    top_p: 1.0
    timeout: 60
    
  # Fast Model for Simple Tasks
  fast:
    provider: "openai"
    model: "gpt-3.5-turbo"
    temperature: 0.3
    max_tokens: 2000
    timeout: 30
    
  # Code-Specialized Model
  code:
    provider: "openai"
    model: "gpt-4"
    temperature: 0.1
    max_tokens: 4000
    timeout: 120
    
  # Creative Writing Model
  creative:
    provider: "anthropic"
    model: "claude-3-opus-20240229"
    temperature: 0.9
    max_tokens: 4000
    timeout: 90

# Embedding Models Configuration
embeddings:
  primary:
    provider: "openai"
    model: "text-embedding-3-large"
    dimensions: 3072
    batch_size: 100
    timeout: 30
    
  fallback:
    provider: "openai"
    model: "text-embedding-ada-002"
    dimensions: 1536
    batch_size: 100
    timeout: 30
    
  fast:
    provider: "sentence-transformers"
    model: "all-MiniLM-L6-v2"
    dimensions: 384
    batch_size: 32
    timeout: 15

# Vision Models Configuration
vision:
  primary:
    provider: "openai"
    model: "gpt-4-vision-preview"
    temperature: 0.7
    max_tokens: 4000
    timeout: 90
    
  image_generation:
    provider: "openai"
    model: "dall-e-3"
    size: "1024x1024"
    quality: "standard"
    timeout: 120

# Audio Models Configuration
audio:
  speech_to_text:
    provider: "openai"
    model: "whisper-1"
    timeout: 120
    
  text_to_speech:
    provider: "openai"
    model: "tts-1"
    voice: "alloy"
    speed: 1.0
    timeout: 60

# Provider-Specific Configurations
providers:
  openai:
    base_url: "https://api.openai.com/v1"
    max_retries: 3
    retry_delay: 1
    request_timeout: 60
    
  anthropic:
    base_url: "https://api.anthropic.com"
    max_retries: 3
    retry_delay: 1
    request_timeout: 60
    
  google:
    base_url: "https://generativelanguage.googleapis.com"
    max_retries: 3
    retry_delay: 1
    request_timeout: 60

# Model Routing Configuration
routing:
  # Route requests based on task type
  task_routing:
    chat: "primary"
    code: "code"
    creative: "creative"
    analysis: "primary"
    summarization: "fast"
    
  # Load balancing configuration
  load_balancing:
    enabled: true
    strategy: "round_robin"  # round_robin, weighted, least_loaded
    
  # Fallback chain
  fallback_chain:
    - "primary"
    - "fallback"
    - "fast"
    
  # Circuit breaker configuration
  circuit_breaker:
    failure_threshold: 5
    timeout: 60
    half_open_max_calls: 3

# Cost and Usage Configuration
cost_management:
  # Token cost per model (USD per 1K tokens)
  token_costs:
    "gpt-4-turbo-preview":
      input: 0.01
      output: 0.03
    "gpt-4":
      input: 0.03
      output: 0.06
    "gpt-3.5-turbo":
      input: 0.0005
      output: 0.0015
    "claude-3-opus-20240229":
      input: 0.015
      output: 0.075
    "claude-3-sonnet-20240229":
      input: 0.003
      output: 0.015
      
  # Usage limits
  daily_limits:
    total_tokens: 1000000
    total_cost: 100.0
    
  # Budget alerts
  budget_alerts:
    - threshold: 0.5  # 50% of budget
      action: "log"
    - threshold: 0.8  # 80% of budget
      action: "warn"
    - threshold: 0.95  # 95% of budget
      action: "throttle"

# Performance Configuration
performance:
  # Connection pooling
  connection_pool:
    max_connections: 100
    max_keepalive_connections: 20
    keepalive_expiry: 300
    
  # Request batching
  batching:
    enabled: true
    max_batch_size: 10
    batch_timeout: 5
    
  # Caching
  response_cache:
    enabled: true
    ttl: 3600
    max_size: 1000
    
  # Rate limiting
  rate_limiting:
    requests_per_minute: 500
    tokens_per_minute: 150000
    burst_allowance: 50

# Model Validation and Testing
validation:
  # Health check configuration
  health_checks:
    enabled: true
    interval: 300  # 5 minutes
    timeout: 30
    
  # Model benchmarking
  benchmarks:
    enabled: false
    test_prompts:
      - "Hello, how are you?"
      - "Explain quantum computing in simple terms."
      - "Write a Python function to calculate factorial."
      
  # A/B testing configuration
  ab_testing:
    enabled: false
    test_percentage: 0.1
    metrics:
      - "response_time"
      - "token_usage"
      - "user_satisfaction"
